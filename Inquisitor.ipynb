{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9Mw6HXDpMVP",
        "outputId": "0e22234e-0a63-4a52-fe53-13fcf39e118e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers torch datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75xYAuR12Mnr",
        "outputId": "12febc7a-1cb3-45ea-d3b5-ae5c2e50495a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Context 0: Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
            "Question 0: To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
            "\n",
            "Context 1: Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
            "Question 1: What is in front of the Notre Dame Main Building?\n",
            "\n",
            "Context 2: Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
            "Question 2: The Basilica of the Sacred heart at Notre Dame is beside to which structure?\n",
            "\n",
            "Epoch 1, Loss: 10.2262\n",
            "Epoch 2, Loss: 9.4369\n",
            "Epoch 3, Loss: 6.5550\n",
            "Epoch 4, Loss: 4.9089\n",
            "Epoch 5, Loss: 4.6112\n"
          ]
        }
      ],
      "source": [
        "# Required Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import DistilBertTokenizer\n",
        "from datasets import load_dataset  # Correct import for load_dataset\n",
        "\n",
        "# Load the SQuAD dataset\n",
        "dataset = load_dataset(\"squad\")\n",
        "\n",
        "# Extract contexts and questions from the dataset\n",
        "contexts = [item['context'] for item in dataset['train']]\n",
        "questions = [item['question'] for item in dataset['train']]\n",
        "\n",
        "# Display the first few contexts and questions to verify\n",
        "for i in range(3):\n",
        "    print(f\"Context {i}: {contexts[i]}\")\n",
        "    print(f\"Question {i}: {questions[i]}\\n\")\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Create a custom Dataset class for Question Generation\n",
        "class QuestionGenerationDataset(Dataset):\n",
        "    def __init__(self, contexts, questions, tokenizer, max_length=512):\n",
        "        self.contexts = contexts\n",
        "        self.questions = questions\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.contexts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        context = self.contexts[idx]\n",
        "        question = self.questions[idx]\n",
        "\n",
        "        # Tokenize context\n",
        "        inputs = self.tokenizer(\n",
        "            context,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Tokenize question\n",
        "        question_inputs = self.tokenizer(\n",
        "            question,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].squeeze(0),  # Remove the batch dimension\n",
        "            'attention_mask': inputs['attention_mask'].squeeze(0),\n",
        "            'labels': question_inputs['input_ids'].squeeze(0)  # Output as labels for training\n",
        "        }\n",
        "\n",
        "# Create the dataset\n",
        "qg_dataset = QuestionGenerationDataset(contexts[:100], questions[:100], tokenizer)\n",
        "\n",
        "# Create DataLoader\n",
        "train_loader = DataLoader(qg_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Define the LSTM-based Question Generation model\n",
        "class LSTMQuestionGenerator(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "        super(LSTMQuestionGenerator, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, input_ids, hidden):\n",
        "        embedded = self.embedding(input_ids)\n",
        "        lstm_out, (hidden, cell) = self.lstm(embedded)\n",
        "        output = self.fc(lstm_out)\n",
        "        return output, (hidden, cell)\n",
        "\n",
        "# Initialize model parameters\n",
        "vocab_size = tokenizer.vocab_size\n",
        "embedding_dim = 128\n",
        "hidden_dim = 256\n",
        "output_dim = vocab_size  # Same as vocab size for output layer\n",
        "\n",
        "# Create the model\n",
        "model = LSTMQuestionGenerator(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch['input_ids']\n",
        "        labels = batch['labels']\n",
        "\n",
        "        # Initialize hidden state\n",
        "        hidden = (torch.zeros(1, input_ids.size(0), hidden_dim),\n",
        "                  torch.zeros(1, input_ids.size(0), hidden_dim))\n",
        "\n",
        "        # Forward pass\n",
        "        outputs, hidden = model(input_ids, hidden)\n",
        "        loss = criterion(outputs.view(-1, output_dim), labels.view(-1))\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {avg_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRQaaitO4h_h",
        "outputId": "aa48f1e3-3009-4195-a87a-8da1e5b88429"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Question: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n"
          ]
        }
      ],
      "source": [
        "def generate_question(model, context, tokenizer, max_length=30):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Tokenize context\n",
        "        inputs = tokenizer(context, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
        "        input_ids = inputs['input_ids']  # Shape: (1, seq_length)\n",
        "        \n",
        "        # Initialize hidden state\n",
        "        hidden = (torch.zeros(1, input_ids.size(0), hidden_dim),\n",
        "                  torch.zeros(1, input_ids.size(0), hidden_dim))\n",
        "        \n",
        "        # Generate output tokens\n",
        "        generated = []\n",
        "        for _ in range(max_length):\n",
        "            output, hidden = model(input_ids, hidden)\n",
        "            next_token = torch.argmax(output[:, -1, :], dim=1)  # Get the most likely next token\n",
        "            \n",
        "            generated.append(next_token.item())\n",
        "            input_ids = torch.cat((input_ids, next_token.unsqueeze(0)), dim=1)  # Append token to input\n",
        "            \n",
        "            # Break if end token is generated\n",
        "            if next_token.item() == tokenizer.eos_token_id: \n",
        "                break\n",
        "\n",
        "    # Convert token IDs to question\n",
        "    return tokenizer.decode(generated, skip_special_tokens=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
